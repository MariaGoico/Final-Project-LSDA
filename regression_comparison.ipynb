{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ce3cf4",
   "metadata": {},
   "source": [
    "# Regression Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0090513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, when, month, lag\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8a578",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29f3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OUTPUT_DIR = \"saved_models\"\n",
    "MASTER_LOG_FILE = \"model_comparison.csv\"\n",
    "BASE_DATA_PATH = \"processed_data\"\n",
    "\n",
    "\n",
    "def get_paths(years):\n",
    "    \"\"\"Generates file paths for the specific years.\"\"\"\n",
    "    return [f\"{BASE_DATA_PATH}/climate_{y}.parquet\" for y in years]\n",
    "\n",
    "def save_training_history(model, output_dir, model_name):\n",
    "    \"\"\"\n",
    "    Extracts iteration history (Objective History) if available.\n",
    "    Works specifically for LinearRegression.\n",
    "    \"\"\"\n",
    "    history_path = os.path.join(output_dir, \"training_history.csv\")\n",
    "    \n",
    "    if hasattr(model, \"summary\") and hasattr(model.summary, \"objectiveHistory\"):\n",
    "        history = model.summary.objectiveHistory\n",
    "        \n",
    "        df_hist = pd.DataFrame({\n",
    "            \"Iteration\": range(1, len(history) + 1),\n",
    "            \"Objective_Loss\": history\n",
    "        })\n",
    "        df_hist.to_csv(history_path, index=False)\n",
    "        print(f\"   [v] Training history (Loss) saved to: {history_path}\")\n",
    "        \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(df_hist[\"Iteration\"], df_hist[\"Objective_Loss\"], marker='o')\n",
    "        plt.title(f\"Convergence Curve - {model_name}\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss (Objective Function)\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_dir, \"convergence_plot.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"   [!] This algorithm does not expose iterative history (objectiveHistory).\")\n",
    "\n",
    "def evaluate_and_log(predictions, target_col, time_taken, output_dir, model_name):\n",
    "    \"\"\"\n",
    "    Calculates metrics, saves them to the Master CSV, and saves a local JSON.\n",
    "    \"\"\"\n",
    "    evaluator = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\")\n",
    "    \n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "    \n",
    "    snow_subset = predictions.filter(col(target_col) > 0)\n",
    "    if snow_subset.count() > 0:\n",
    "        r2_snow = evaluator.setMetricName(\"r2\").evaluate(snow_subset)\n",
    "    else:\n",
    "        r2_snow = 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Time_Sec\": round(time_taken, 2),\n",
    "        \"R2_Global\": round(r2, 4),\n",
    "        \"RMSE_Global\": round(rmse, 4),\n",
    "        \"MAE_Global\": round(mae, 4),\n",
    "        \"R2_Snow_Only\": round(r2_snow, 4)\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(MASTER_LOG_FILE)\n",
    "    with open(MASTER_LOG_FILE, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"metrics.json\"), 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    print(f\"\\n--- METRICS ({model_name}) ---\")\n",
    "    print(f\"R2: {r2:.4f} | RMSE: {rmse:.4f} | R2 Snow Only: {r2_snow:.4f}\")\n",
    "    return metrics\n",
    "\n",
    "def plot_predictions(predictions, target_col, output_dir, model_name):\n",
    "    \"\"\"Generates and saves Scatter and Residual plots.\"\"\"\n",
    "    print(\"   Generating plots...\")\n",
    "    \n",
    "    pdf = predictions.select(target_col, \"prediction\").sample(False, 0.05, seed=42).toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(x=pdf[target_col], y=pdf[\"prediction\"], alpha=0.3)\n",
    "    plt.plot([pdf[target_col].min(), pdf[target_col].max()], \n",
    "             [pdf[target_col].min(), pdf[target_col].max()], 'r--', lw=2)\n",
    "    plt.xlabel('Reality (Actual Value)')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title(f'Prediction vs Reality - {model_name}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = pdf[target_col] - pdf[\"prediction\"]\n",
    "    sns.histplot(residuals, bins=50, kde=True)\n",
    "    plt.xlabel('Error (Real - Predicted)')\n",
    "    plt.title('Residuals Distribution')\n",
    "    \n",
    "    plt.savefig(os.path.join(output_dir, \"prediction_plots.png\"))\n",
    "    plt.close()\n",
    "    print(f\"   [v] Plots saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd02204",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2596fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING: LinearRegression_Baseline ---\n",
      "Output Directory: saved_models/LinearRegression_Baseline\n",
      "1. Loading Data (Full Dataset)...\n",
      "   Features (19): ['LATITUDE', 'LONGITUDE', 'ELEVATION', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN', 'PRCP', 'is_Fog', 'is_Rain', 'is_Snow', 'is_Hail', 'is_Thunder', 'is_Tornado']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Rows: 51,241,804\n",
      "2. Training LinearRegression_Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training completed in 49.48 seconds.\n",
      "3. Processing Results...\n",
      "   [v] Spark Model saved to: saved_models/LinearRegression_Baseline/spark_model\n",
      "   [v] Training history (Loss) saved to: saved_models/LinearRegression_Baseline/training_history.csv\n",
      "   Generating predictions on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- METRICS (LinearRegression_Baseline) ---\n",
      "R2: 0.3790 | RMSE: 9.0236 | R2 Snow Only: 0.0118\n",
      "   Generating plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [v] Plots saved in: saved_models/LinearRegression_Baseline\n",
      "\n",
      "--- PROCESS FINISHED SUCCESSFULLY ---\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"LinearRegression_Baseline\"\n",
    "\n",
    "print(f\"--- STARTING: {MODEL_NAME} ---\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(MODEL_NAME) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "model_output_dir = os.path.join(BASE_OUTPUT_DIR, MODEL_NAME)\n",
    "if os.path.exists(model_output_dir):\n",
    "    shutil.rmtree(model_output_dir)\n",
    "os.makedirs(model_output_dir)\n",
    "\n",
    "print(f\"Output Directory: {model_output_dir}\")\n",
    "\n",
    "train_years = range(2010, 2021) \n",
    "val_years   = range(2021, 2023) \n",
    "test_years  = range(2023, 2025) \n",
    "\n",
    "print(\"1. Loading Data (Full Dataset)...\")\n",
    "try:\n",
    "    train_df = spark.read.parquet(*get_paths(train_years))\n",
    "    val_df   = spark.read.parquet(*get_paths(val_years))\n",
    "    test_df  = spark.read.parquet(*get_paths(test_years))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    spark.stop()\n",
    "    raise e\n",
    "\n",
    "target_col = \"SNDP\"\n",
    "ignore_cols = [target_col, \"DATE\", \"STATION\", \"NAME\", \"features\", \"prediction\", \"FRSHTT\"]\n",
    "valid_types = ['int', 'bigint', 'float', 'double', 'tinyint', 'smallint']\n",
    "\n",
    "dtypes = train_df.dtypes\n",
    "feature_cols = [c for c, t in dtypes if t in valid_types and c not in ignore_cols]\n",
    "print(f\"   Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "\n",
    "train_vec = assembler.transform(train_df)\n",
    "val_vec   = assembler.transform(val_df)\n",
    "test_vec  = assembler.transform(test_df)\n",
    "\n",
    "train_vec.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "print(f\"   Training Rows: {train_vec.count():,}\")\n",
    "\n",
    "print(f\"2. Training {MODEL_NAME}...\")\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=target_col,\n",
    "    maxIter=50, \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=0.5\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model = lr.fit(train_vec)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"   Training completed in {duration:.2f} seconds.\")\n",
    "\n",
    "print(\"3. Processing Results...\")\n",
    "\n",
    "model_save_path = os.path.join(model_output_dir, \"spark_model\")\n",
    "model.write().overwrite().save(model_save_path)\n",
    "print(f\"   [v] Spark Model saved to: {model_save_path}\")\n",
    "\n",
    "save_training_history(model, model_output_dir, MODEL_NAME)\n",
    "\n",
    "print(\"   Generating predictions on Test Set...\")\n",
    "test_preds = model.transform(test_vec)\n",
    "metrics = evaluate_and_log(test_preds, target_col, duration, model_output_dir, MODEL_NAME)\n",
    "\n",
    "plot_predictions(test_preds, target_col, model_output_dir, MODEL_NAME)\n",
    "\n",
    "print(\"\\n--- PROCESS FINISHED SUCCESSFULLY ---\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5868c6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b6a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OUTPUT_DIR = \"saved_models\"     \n",
    "MASTER_LOG_FILE = \"model_comparison.csv\" \n",
    "BASE_DATA_PATH = \"processed_data\"    \n",
    "\n",
    "def get_paths(years):\n",
    "    return [f\"{BASE_DATA_PATH}/climate_{y}.parquet\" for y in years]\n",
    "\n",
    "def save_feature_importance(model, feature_cols, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts Feature Importance from Random Forest and saves it to CSV.\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"featureImportances\"):\n",
    "        importances = model.featureImportances\n",
    "        feature_list = []\n",
    "        for i, col_name in enumerate(feature_cols):\n",
    "            feature_list.append({\"Feature\": col_name, \"Importance\": float(importances[i])})\n",
    "        \n",
    "        df_imp = pd.DataFrame(feature_list).sort_values(by=\"Importance\", ascending=False)\n",
    "        csv_path = os.path.join(output_dir, \"feature_importance.csv\")\n",
    "        df_imp.to_csv(csv_path, index=False)\n",
    "        print(f\"   [v] Feature Importance saved to: {csv_path}\")\n",
    "        \n",
    "        print(\"   --- TOP 5 FEATURES ---\")\n",
    "        print(df_imp.head(5))\n",
    "    else:\n",
    "        print(\"   [!] This model does not support feature importance.\")\n",
    "\n",
    "def evaluate_and_log(predictions, target_col, time_taken, output_dir, model_name):\n",
    "    \"\"\"\n",
    "    Calculates R2, RMSE, MAE, saves to Master CSV and local JSON.\n",
    "    \"\"\"\n",
    "    evaluator = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\")\n",
    "    \n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "    \n",
    "    snow_subset = predictions.filter(col(target_col) > 0)\n",
    "    if snow_subset.count() > 0:\n",
    "        r2_snow = evaluator.setMetricName(\"r2\").evaluate(snow_subset)\n",
    "    else:\n",
    "        r2_snow = 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Time_Sec\": round(time_taken, 2),\n",
    "        \"R2_Global\": round(r2, 4),\n",
    "        \"RMSE_Global\": round(rmse, 4),\n",
    "        \"MAE_Global\": round(mae, 4),\n",
    "        \"R2_Snow_Only\": round(r2_snow, 4)\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(MASTER_LOG_FILE)\n",
    "    with open(MASTER_LOG_FILE, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"metrics.json\"), 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    print(f\"\\n--- METRICS ({model_name}) ---\")\n",
    "    print(f\"R2: {r2:.4f} | RMSE: {rmse:.4f} | R2 Snow Only: {r2_snow:.4f}\")\n",
    "    return metrics\n",
    "\n",
    "def plot_predictions(predictions, target_col, output_dir, model_name):\n",
    "    \"\"\"Generates and saves Scatter and Residual plots.\"\"\"\n",
    "    print(\"   Generating plots...\")\n",
    "    \n",
    "    pdf = predictions.select(target_col, \"prediction\").sample(False, 0.05, seed=42).toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(x=pdf[target_col], y=pdf[\"prediction\"], alpha=0.3)\n",
    "    plt.plot([pdf[target_col].min(), pdf[target_col].max()], \n",
    "             [pdf[target_col].min(), pdf[target_col].max()], 'r--', lw=2)\n",
    "    plt.xlabel('Reality (Actual Value)')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title(f'Prediction vs Reality - {model_name}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = pdf[target_col] - pdf[\"prediction\"]\n",
    "    sns.histplot(residuals, bins=50, kde=True)\n",
    "    plt.xlabel('Error (Real - Predicted)')\n",
    "    plt.title('Residuals Distribution')\n",
    "    \n",
    "    plt.savefig(os.path.join(output_dir, \"prediction_plots.png\"))\n",
    "    plt.close()\n",
    "    print(f\"   [v] Plots saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f79b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING: RandomForest_Baseline ---\n",
      "1. Loading Data...\n",
      "   Features (19): ['LATITUDE', 'LONGITUDE', 'ELEVATION', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN', 'PRCP', 'is_Fog', 'is_Rain', 'is_Snow', 'is_Hail', 'is_Thunder', 'is_Tornado']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Rows: 51,241,804\n",
      "2. Training RandomForest_Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training completed in 1564.64 seconds.\n",
      "3. Processing Results...\n",
      "   [v] Feature Importance saved to: saved_models/RandomForest_Baseline/feature_importance.csv\n",
      "   --- TOP 5 FEATURES ---\n",
      "     Feature  Importance\n",
      "11       MIN    0.326477\n",
      "10       MAX    0.233745\n",
      "3       TEMP    0.129317\n",
      "0   LATITUDE    0.072881\n",
      "4       DEWP    0.067982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- METRICS (RandomForest_Baseline) ---\n",
      "R2: 0.6211 | RMSE: 7.0489 | R2 Snow Only: 0.3284\n",
      "   Generating plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [v] Plots saved in: saved_models/RandomForest_Baseline\n",
      "\n",
      "--- PROCESS FINISHED ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel\n",
    "import pyspark.sql.functions as sql_f\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "\n",
    "\"\"\"\n",
    "PySpark ML implementation for scalability experiments\n",
    "\"\"\"\n",
    "\n",
    "BASE_DATA_PATH = \"processed_data\"  # adjust to your path\n",
    "BASE_OUTPUT_DIR = \"model_outputs\"\n",
    "TARGET_COL = \"SNDP\"      # target column\n",
    "IGNORE_COLS = [TARGET_COL, \"DATE\", \"STATION\", \"NAME\", \"features\", \"prediction\", \"FRSHTT\"]\n",
    "VALID_TYPES = ['int', 'bigint', 'float', 'double', 'tinyint', 'smallint']\n",
    "\n",
    "MODEL_TYPE = \"regression\"  # \"regression\" or \"classification\"\n",
    "\n",
    "\n",
    "def get_paths(years):\n",
    "    return [f\"{BASE_DATA_PATH}/climate_{y}.parquet\" for y in years]\n",
    "\n",
    "\n",
    "def evaluate_model(predictions_df, target_col, model_type):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions\n",
    "    \"\"\"\n",
    "    if model_type == \"regression\":\n",
    "        evaluator = RegressionEvaluator(\n",
    "            labelCol=target_col,\n",
    "            predictionCol=\"prediction\",\n",
    "            metricName=\"rmse\"\n",
    "        )\n",
    "        rmse = evaluator.evaluate(predictions_df)\n",
    "        return rmse\n",
    "    else:\n",
    "        evaluator = MulticlassClassificationEvaluator(\n",
    "            labelCol=target_col,\n",
    "            predictionCol=\"prediction\",\n",
    "            metricName=\"accuracy\"\n",
    "        )\n",
    "        accuracy = evaluator.evaluate(predictions_df)\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    # Parse arguments\n",
    "    cores = int(argv[0])            # number of partitions / Spark cores\n",
    "    pct = int(argv[1])              # percentage of training data to use\n",
    "    filename = argv[2] if len(argv) > 2 else \"scalability_results.csv\"\n",
    "\n",
    "    MODEL_NAME = f\"DecisionTree_cores{cores}_pct{pct}\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"--- STARTING: {MODEL_NAME} ---\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Start Spark\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(MODEL_NAME)\n",
    "        .master(f\"local[{cores}]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.files.maxPartitionBytes\", \"128m\")\n",
    "        .config(\"spark.driver.maxResultSize\", \"4g\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "    # Create output directory\n",
    "    model_output_dir = os.path.join(BASE_OUTPUT_DIR, MODEL_NAME)\n",
    "    if os.path.exists(model_output_dir):\n",
    "        shutil.rmtree(model_output_dir)\n",
    "    os.makedirs(model_output_dir)\n",
    "\n",
    "    # Define data splits\n",
    "    train_years = range(2021, 2023)\n",
    "    val_years   = range(2023, 2024)\n",
    "\n",
    "    print(\"1. Loading Data...\")\n",
    "    try:\n",
    "        df_train = spark.read.parquet(*get_paths(train_years))\n",
    "        df_val   = spark.read.parquet(*get_paths(val_years))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        spark.stop()\n",
    "        raise e\n",
    "\n",
    "    # Select features\n",
    "    dtypes = df_train.dtypes\n",
    "    feature_cols = [c for c, t in dtypes if t in VALID_TYPES and c not in IGNORE_COLS]\n",
    "    print(f\"   Features ({len(feature_cols)}): {feature_cols[:5]}... (showing first 5)\")\n",
    "\n",
    "    # Prepare training data\n",
    "    df_train = df_train.select(feature_cols + [TARGET_COL])\n",
    "    \n",
    "    # Sample fraction if pct < 100\n",
    "    if pct < 100:\n",
    "        print(f\"   Sampling {pct}% of training data...\")\n",
    "        df_train = df_train.sample(fraction=pct/100.0, seed=42)\n",
    "\n",
    "    # Repartition training data\n",
    "    df_train = df_train.repartition(cores)\n",
    "    \n",
    "    # Assemble features\n",
    "    print(\"   Assembling features...\")\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "    train_vec = assembler.transform(df_train)\n",
    "    val_vec = assembler.transform(df_val)\n",
    "\n",
    "    # Cache and materialize\n",
    "    train_vec.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "    train_count = train_vec.count()\n",
    "    print(f\"   Training Rows: {train_count:,}\")\n",
    "    print(f\"   Partitions: {train_vec.rdd.getNumPartitions()}\")\n",
    "\n",
    "    # Build model\n",
    "    print(f\"\\n2. Training {MODEL_NAME}...\")\n",
    "    if MODEL_TYPE == \"regression\":\n",
    "        model = DecisionTreeRegressor(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=TARGET_COL,\n",
    "            maxDepth=15,\n",
    "            seed=42\n",
    "        )\n",
    "    else:\n",
    "        model = DecisionTreeClassifier(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=TARGET_COL,\n",
    "            maxDepth=15,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "    start_time = time.time()\n",
    "    fitted_model = model.fit(train_vec)\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_runtime = end_time - start_time\n",
    "    print(f\"   Training completed in {total_runtime:.2f} seconds.\")\n",
    "\n",
    "    # Save model\n",
    "    print(\"\\n3. Saving Model...\")\n",
    "    fitted_model.write().overwrite().save(os.path.join(model_output_dir, \"spark_model\"))\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    print(\"\\n4. Evaluating on Validation Set...\")\n",
    "    val_preds = fitted_model.transform(val_vec)\n",
    "    accuracy = evaluate_model(val_preds, TARGET_COL, MODEL_TYPE)\n",
    "    \n",
    "    metric_name = \"RMSE\" if MODEL_TYPE == \"regression\" else \"Accuracy\"\n",
    "    print(f\"   Validation {metric_name}: {accuracy:.4f}\")\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY:\")\n",
    "    print(f\"  Cores: {cores}\")\n",
    "    print(f\"  Data fraction: {pct}%\")\n",
    "    print(f\"  Training rows: {train_count:,}\")\n",
    "    print(f\"  Total runtime: {total_runtime:.2f}s\")\n",
    "    print(f\"  Validation {metric_name}: {accuracy:.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Log results to CSV\n",
    "    with open(filename, \"a\") as f:\n",
    "        # Format: cores, pct, total_runtime, train_count, accuracy\n",
    "        print(f\"{cores},{pct},{total_runtime},{train_count},{accuracy}\", file=f)\n",
    "\n",
    "    # Cleanup\n",
    "    train_vec.unpersist()\n",
    "    spark.stop()\n",
    "    \n",
    "    print(\"--- PROCESS FINISHED ---\\n\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Entry point\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c321a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING: RandomForest_New_Features ---\n",
      "1. Loading Data...\n",
      "2. Applying Feature Engineering (Month + Solid_PRCP)...\n",
      "   Features (21): ['LATITUDE', 'LONGITUDE', 'ELEVATION', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN', 'PRCP', 'is_Fog', 'is_Rain', 'is_Snow', 'is_Hail', 'is_Thunder', 'is_Tornado', 'MONTH', 'Solid_PRCP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Rows: 51,241,804\n",
      "3. Training RandomForest_New_Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training completed in 1778.49 seconds.\n",
      "4. Processing Results...\n",
      "   [v] Feature Importance saved to: saved_models/RandomForest_New_Features/feature_importance.csv\n",
      "   --- TOP 5 FEATURES ---\n",
      "   Feature  Importance\n",
      "11     MIN    0.273749\n",
      "10     MAX    0.217890\n",
      "3     TEMP    0.105897\n",
      "19   MONTH    0.095371\n",
      "4     DEWP    0.073162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- METRICS (RandomForest_New_Features) ---\n",
      "R2: 0.6995 | RMSE: 6.2765 | R2 Snow Only: 0.4675\n",
      "   Generating plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [v] Plots saved in: saved_models/RandomForest_New_Features\n",
      "\n",
      "--- PROCESS FINISHED ---\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"RandomForest_New_Features\"\n",
    "\n",
    "print(f\"--- STARTING: {MODEL_NAME} ---\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(MODEL_NAME) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "model_output_dir = os.path.join(BASE_OUTPUT_DIR, MODEL_NAME)\n",
    "if os.path.exists(model_output_dir):\n",
    "    shutil.rmtree(model_output_dir)\n",
    "os.makedirs(model_output_dir)\n",
    "\n",
    "train_years = range(2010, 2021) \n",
    "val_years   = range(2021, 2023) \n",
    "test_years  = range(2023, 2025) \n",
    "\n",
    "print(\"1. Loading Data...\")\n",
    "try:\n",
    "    train_raw = spark.read.parquet(*get_paths(train_years))\n",
    "    val_raw   = spark.read.parquet(*get_paths(val_years))\n",
    "    test_raw  = spark.read.parquet(*get_paths(test_years))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    spark.stop()\n",
    "    raise e\n",
    "\n",
    "print(\"2. Applying Feature Engineering (Month + Solid_PRCP)...\")\n",
    "\n",
    "def add_smart_features(df):\n",
    "    df = df.withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "    df = df.withColumn(\n",
    "        \"Solid_PRCP\", \n",
    "        when((col(\"PRCP\") > 0) & (col(\"TEMP\") < 2.0), col(\"PRCP\")).otherwise(0.0)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_df = add_smart_features(train_raw)\n",
    "val_df   = add_smart_features(val_raw)\n",
    "test_df  = add_smart_features(test_raw)\n",
    "\n",
    "target_col = \"SNDP\"\n",
    "ignore_cols = [target_col, \"DATE\", \"STATION\", \"NAME\", \"features\", \"prediction\", \"FRSHTT\"]\n",
    "valid_types = ['int', 'bigint', 'float', 'double', 'tinyint', 'smallint']\n",
    "\n",
    "dtypes = train_df.dtypes\n",
    "feature_cols = [c for c, t in dtypes if t in valid_types and c not in ignore_cols]\n",
    "print(f\"   Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "\n",
    "train_vec = assembler.transform(train_df)\n",
    "val_vec   = assembler.transform(val_df)\n",
    "test_vec  = assembler.transform(test_df)\n",
    "\n",
    "train_vec.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "print(f\"   Training Rows: {train_vec.count():,}\")\n",
    "\n",
    "print(f\"3. Training {MODEL_NAME}...\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=target_col,\n",
    "    numTrees=40,         \n",
    "    maxDepth=10,         \n",
    "    seed=42,\n",
    "    subsamplingRate=0.7 \n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model = rf.fit(train_vec)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"   Training completed in {duration:.2f} seconds.\")\n",
    "\n",
    "print(\"4. Processing Results...\")\n",
    "\n",
    "model.write().overwrite().save(os.path.join(model_output_dir, \"spark_model\"))\n",
    "save_feature_importance(model, feature_cols, model_output_dir)\n",
    "\n",
    "test_preds = model.transform(test_vec)\n",
    "metrics = evaluate_and_log(test_preds, target_col, duration, model_output_dir, MODEL_NAME)\n",
    "\n",
    "plot_predictions(test_preds, target_col, model_output_dir, MODEL_NAME)\n",
    "\n",
    "print(\"\\n--- PROCESS FINISHED ---\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb9ec0",
   "metadata": {},
   "source": [
    "## GBT Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a52cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING: GBT_New_Features ---\n",
      "1. Loading Data...\n",
      "2. Applying Feature Engineering (Month + Solid_PRCP)...\n",
      "   Features (21): ['LATITUDE', 'LONGITUDE', 'ELEVATION', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN', 'PRCP', 'is_Fog', 'is_Rain', 'is_Snow', 'is_Hail', 'is_Thunder', 'is_Tornado', 'MONTH', 'Solid_PRCP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Rows: 51,241,804\n",
      "3. Training GBT_New_Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training completed in 8294.65 seconds.\n",
      "4. Processing Results...\n",
      "   [v] Feature Importance saved to: saved_models/GBT_New_Features/feature_importance.csv\n",
      "   --- TOP 5 FEATURES ---\n",
      "      Feature  Importance\n",
      "10        MAX    0.270098\n",
      "1   LONGITUDE    0.170592\n",
      "0    LATITUDE    0.152985\n",
      "2   ELEVATION    0.143522\n",
      "19      MONTH    0.111063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- METRICS (GBT_New_Features) ---\n",
      "R2: 0.6998 | RMSE: 6.2742 | R2 Snow Only: 0.4696\n",
      "   Generating plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [v] Plots saved in: saved_models/GBT_New_Features\n",
      "\n",
      "--- PROCESS FINISHED ---\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"GBT_New_Features\"\n",
    "\n",
    "print(f\"--- STARTING: {MODEL_NAME} ---\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(MODEL_NAME) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "model_output_dir = os.path.join(BASE_OUTPUT_DIR, MODEL_NAME)\n",
    "if os.path.exists(model_output_dir):\n",
    "    shutil.rmtree(model_output_dir)\n",
    "os.makedirs(model_output_dir)\n",
    "\n",
    "train_years = range(2010, 2021) \n",
    "val_years   = range(2021, 2023) \n",
    "test_years  = range(2023, 2025) \n",
    "\n",
    "print(\"1. Loading Data...\")\n",
    "try:\n",
    "    train_raw = spark.read.parquet(*get_paths(train_years))\n",
    "    val_raw   = spark.read.parquet(*get_paths(val_years))\n",
    "    test_raw  = spark.read.parquet(*get_paths(test_years))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    spark.stop()\n",
    "    raise e\n",
    "\n",
    "print(\"2. Applying Feature Engineering (Month + Solid_PRCP)...\")\n",
    "\n",
    "def add_smart_features(df):\n",
    "    df = df.withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "    df = df.withColumn(\n",
    "        \"Solid_PRCP\", \n",
    "        when((col(\"PRCP\") > 0) & (col(\"TEMP\") < 2.0), col(\"PRCP\")).otherwise(0.0)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_df = add_smart_features(train_raw)\n",
    "val_df   = add_smart_features(val_raw)\n",
    "test_df  = add_smart_features(test_raw)\n",
    "\n",
    "target_col = \"SNDP\"\n",
    "ignore_cols = [target_col, \"DATE\", \"STATION\", \"NAME\", \"features\", \"prediction\", \"FRSHTT\"]\n",
    "valid_types = ['int', 'bigint', 'float', 'double', 'tinyint', 'smallint']\n",
    "\n",
    "dtypes = train_df.dtypes\n",
    "feature_cols = [c for c, t in dtypes if t in valid_types and c not in ignore_cols]\n",
    "print(f\"   Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "\n",
    "train_vec = assembler.transform(train_df)\n",
    "val_vec   = assembler.transform(val_df)\n",
    "test_vec  = assembler.transform(test_df)\n",
    "\n",
    "train_vec.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "print(f\"   Training Rows: {train_vec.count():,}\")\n",
    "\n",
    "print(f\"3. Training {MODEL_NAME}...\")\n",
    "\n",
    "gbt = GBTRegressor(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=target_col,\n",
    "    maxIter=50,         \n",
    "    maxDepth=5,         \n",
    "    stepSize=0.1,\n",
    "    seed=42,\n",
    "    subsamplingRate=0.7 \n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model = gbt.fit(train_vec)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"   Training completed in {duration:.2f} seconds.\")\n",
    "\n",
    "print(\"4. Processing Results...\")\n",
    "\n",
    "model.write().overwrite().save(os.path.join(model_output_dir, \"spark_model\"))\n",
    "save_feature_importance(model, feature_cols, model_output_dir)\n",
    "\n",
    "test_preds = model.transform(test_vec)\n",
    "metrics = evaluate_and_log(test_preds, target_col, duration, model_output_dir, MODEL_NAME)\n",
    "\n",
    "plot_predictions(test_preds, target_col, model_output_dir, MODEL_NAME)\n",
    "\n",
    "print(\"\\n--- PROCESS FINISHED ---\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6485c7a",
   "metadata": {},
   "source": [
    "## Hypertuning of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3af9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OUTPUT_DIR = \"optimized_models\"     \n",
    "MASTER_LOG_FILE = \"tuning_comparison.csv\" \n",
    "BASE_DATA_PATH = \"processed_data\"    \n",
    "\n",
    "def get_paths(years):\n",
    "    return [f\"{BASE_DATA_PATH}/climate_{y}.parquet\" for y in years]\n",
    "\n",
    "def save_best_params(cv_model, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts and saves the best hyperparameters found by CrossValidator.\n",
    "    \"\"\"\n",
    "    rf_model = cv_model.bestModel\n",
    "    \n",
    "    params = {\n",
    "        \"numTrees\": rf_model.getNumTrees,\n",
    "        \"maxDepth\": rf_model.getOrDefault(\"maxDepth\"),\n",
    "        \"maxBins\": rf_model.getOrDefault(\"maxBins\"),\n",
    "        \"subsamplingRate\": rf_model.getOrDefault(\"subsamplingRate\")\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"best_params.json\"), 'w') as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "    \n",
    "    print(\"\\n   [v] WINNING PARAMETERS SAVED:\")\n",
    "    print(json.dumps(params, indent=4))\n",
    "\n",
    "def evaluate_and_log(predictions, target_col, time_taken, output_dir, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the final Test set.\n",
    "    \"\"\"\n",
    "    evaluator = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\")\n",
    "    \n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "    \n",
    "    snow_subset = predictions.filter(col(target_col) > 0)\n",
    "    r2_snow = evaluator.setMetricName(\"r2\").evaluate(snow_subset) if snow_subset.count() > 0 else 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Time_Min\": round(time_taken / 60, 2),\n",
    "        \"R2_Global\": round(r2, 4),\n",
    "        \"RMSE_Global\": round(rmse, 4),\n",
    "        \"R2_Snow_Only\": round(r2_snow, 4)\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(MASTER_LOG_FILE)\n",
    "    with open(MASTER_LOG_FILE, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "    print(f\"\\n--- FINAL TEST RESULTS ({model_name}) ---\")\n",
    "    print(f\"R2 Global: {r2:.4f} | R2 Snow Only: {r2_snow:.4f}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414248fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING TUNING: RandomForest_HyperTuning ---\n",
      "1. Loading and Transforming Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features to use: ['LATITUDE', 'LONGITUDE', 'ELEVATION', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN', 'PRCP', 'is_Fog', 'is_Rain', 'is_Snow', 'is_Hail', 'is_Thunder', 'is_Tornado', 'MONTH', 'Solid_PRCP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Rows (Internal Train + Val): 51,241,804\n",
      "2. Configuring Grid Search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original Training Rows: 51,241,804\n",
      "   Combinations to test: 4\n",
      "3. Running Time-Aware Hyperparameter Search...\n",
      "   [1/4] Training with params: numTrees=50, maxDepth=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 351:============>    (5 + 2) / 7][Stage 360:>                (0 + 2) / 5]\r"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"RandomForest_HyperTuning\"\n",
    "print(f\"--- STARTING TUNING: {MODEL_NAME} ---\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(MODEL_NAME) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "model_output_dir = os.path.join(BASE_OUTPUT_DIR, MODEL_NAME)\n",
    "if os.path.exists(model_output_dir):\n",
    "    shutil.rmtree(model_output_dir)\n",
    "os.makedirs(model_output_dir)\n",
    "\n",
    "train_years = range(2010, 2021) \n",
    "val_years   = range(2021, 2023) \n",
    "test_years  = range(2023, 2025) \n",
    "\n",
    "print(\"1. Loading and Transforming Data...\")\n",
    "train_raw = spark.read.parquet(*get_paths(train_years))\n",
    "val_raw  = spark.read.parquet(*get_paths(val_years))\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "    df = df.withColumn(\"Solid_PRCP\", when((col(\"PRCP\") > 0) & (col(\"TEMP\") < 2.0), col(\"PRCP\")).otherwise(0.0))\n",
    "    return df\n",
    "\n",
    "train_df = add_features(train_raw)\n",
    "val_df  = add_features(val_raw)\n",
    "\n",
    "target_col = \"SNDP\"\n",
    "ignore_cols = [target_col, \"DATE\", \"STATION\", \"NAME\", \"features\", \"prediction\", \"FRSHTT\"]\n",
    "valid_types = ['int', 'bigint', 'float', 'double', 'tinyint', 'smallint']\n",
    "\n",
    "dtypes = train_df.dtypes\n",
    "feature_cols = [c for c, t in dtypes if t in valid_types and c not in ignore_cols]\n",
    "print(f\"   Features to use: {feature_cols}\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "\n",
    "train_vec = assembler.transform(train_df)\n",
    "val_vec  = assembler.transform(val_df)\n",
    "\n",
    "train_vec.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "print(f\"   Training Rows (Internal Train + Val): {train_vec.count():,}\")\n",
    "\n",
    "print(\"2. Configuring Grid Search...\")\n",
    "\n",
    "print(f\"   Original Training Rows: {train_vec.count():,}\")\n",
    "\n",
    "# # --- ADD THIS SAMPLING STEP ---\n",
    "# # Take 10% of data for the heavy tuning process\n",
    "# train_vec_sample = train_vec.sample(False, 0.2, seed=42) \n",
    "# train_vec_sample.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# print(f\"   Tuning Sample Rows: {train_vec_sample.count():,}\")\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=target_col, seed=42)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 25]) \\\n",
    "    .addGrid(rf.maxDepth, [15, 10]) \\\n",
    "    .build()\n",
    "    # .addGrid(rf.maxBins, [32, 64]) \\\n",
    "\n",
    "print(f\"   Combinations to test: {len(paramGrid)}\")\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# tvs = TrainValidationSplit(\n",
    "#     estimator=rf,\n",
    "#     estimatorParamMaps=paramGrid,\n",
    "#     evaluator=evaluator,\n",
    "#     trainRatio=0.8,\n",
    "#     parallelism=1\n",
    "# )\n",
    "\n",
    "\n",
    "# print(\"3. Running Train-Validation Split (Please wait)...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# cv_model = tvs.fit(train_vec)\n",
    "\n",
    "# end_time = time.time()\n",
    "# duration = end_time - start_time\n",
    "# print(f\"   Tuning completed in {duration/60:.2f} minutes!\")\n",
    "\n",
    "# print(\"4. Analyzing the Champion Model...\")\n",
    "\n",
    "# best_model = cv_model.bestModel\n",
    "\n",
    "print(\"3. Running Time-Aware Hyperparameter Search...\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, param_map in enumerate(paramGrid, 1):\n",
    "    print(f\"   [{i}/{len(paramGrid)}] Training with params: \"\n",
    "          f\"numTrees={param_map[rf.numTrees]}, \"\n",
    "          f\"maxDepth={param_map[rf.maxDepth]}\")\n",
    "\n",
    "    # Train ONLY on past data\n",
    "    model = rf.copy(param_map).fit(train_vec)\n",
    "\n",
    "    # Validate ONLY on future data\n",
    "    val_preds = model.transform(val_vec)\n",
    "    rmse = evaluator.evaluate(val_preds)\n",
    "\n",
    "    print(f\"       RMSE = {rmse:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"numTrees\": param_map[rf.numTrees],\n",
    "        \"maxDepth\": param_map[rf.maxDepth],\n",
    "        \"rmse\": rmse,\n",
    "        \"model\": model\n",
    "    })\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"   Tuning completed in {duration/60:.2f} minutes!\")\n",
    "\n",
    "best_result = min(results, key=lambda x: x[\"rmse\"])\n",
    "best_model = best_result[\"model\"]\n",
    "\n",
    "print(\"\\n4. Best Model Selected:\")\n",
    "print(f\"   numTrees = {best_result['numTrees']}\")\n",
    "print(f\"   maxDepth = {best_result['maxDepth']}\")\n",
    "print(f\"   RMSE     = {best_result['rmse']:.4f}\")\n",
    "\n",
    "best_model.write().overwrite().save(\n",
    "    os.path.join(model_output_dir, \"spark_model_winner\")\n",
    ")\n",
    "\n",
    "save_best_params(best_result, model_output_dir)\n",
    "\n",
    "print(\"\\n--- PROCESS FINISHED ---\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5409afd",
   "metadata": {},
   "source": [
    "## Lag Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"RF_Lags_Tuned\"\n",
    "Previous_Tuning_Dir = \"optimized_models/RandomForest_HyperTuning\"\n",
    "BASE_OUTPUT_DIR = \"saved_models\"\n",
    "MASTER_LOG_FILE = \"model_comparison.csv\"\n",
    "BASE_DATA_PATH = \"processed_data\"\n",
    "\n",
    "print(f\"--- STARTING THE ULTIMATE MODEL: {MODEL_NAME} ---\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(MODEL_NAME) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "model_output_dir = os.path.join(BASE_OUTPUT_DIR, MODEL_NAME)\n",
    "if os.path.exists(model_output_dir):\n",
    "    shutil.rmtree(model_output_dir)\n",
    "os.makedirs(model_output_dir)\n",
    "\n",
    "def evaluate_and_log(predictions, target_col, time_taken, output_dir, model_name):\n",
    "    \"\"\"Calculates metrics and appends them to the Master CSV.\"\"\"\n",
    "    evaluator = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\")\n",
    "    \n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "    \n",
    "    snow_subset = predictions.filter(col(target_col) > 0)\n",
    "    r2_snow = evaluator.setMetricName(\"r2\").evaluate(snow_subset) if snow_subset.count() > 0 else 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Time_Min\": round(time_taken / 60, 2),\n",
    "        \"R2_Global\": round(r2, 4),\n",
    "        \"RMSE_Global\": round(rmse, 4),\n",
    "        \"MAE_Global\": round(mae, 4),\n",
    "        \"R2_Snow_Only\": round(r2_snow, 4)\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(MASTER_LOG_FILE)\n",
    "    with open(MASTER_LOG_FILE, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"metrics.json\"), 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    print(f\"\\n--- RESULTS ({model_name}) ---\")\n",
    "    print(f\"R2 Global: {r2:.4f} | R2 Snow Only: {r2_snow:.4f}\")\n",
    "    return metrics\n",
    "\n",
    "print(\"1. Loading best parameters from previous Tuning...\")\n",
    "\n",
    "params_file = os.path.join(Previous_Tuning_Dir, \"best_params.json\")\n",
    "\n",
    "try:\n",
    "    with open(params_file, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    print(\"   [v] Parameters loaded successfully:\")\n",
    "    print(json.dumps(best_params, indent=4))\n",
    "except FileNotFoundError:\n",
    "    print(f\"   [!] ERROR: {params_file} not found. Make sure the Tuning step finished successfully.\")\n",
    "    spark.stop()\n",
    "    raise\n",
    "\n",
    "\n",
    "train_years = range(2010, 2021) \n",
    "test_years  = range(2023, 2025) \n",
    "\n",
    "def get_paths(years):\n",
    "    return [f\"{BASE_DATA_PATH}/climate_{y}.parquet\" for y in years]\n",
    "\n",
    "print(\"2. Loading data and generating Lags...\")\n",
    "train_raw = spark.read.parquet(*get_paths(train_years))\n",
    "test_raw  = spark.read.parquet(*get_paths(test_years))\n",
    "\n",
    "def add_features_with_lags(df):\n",
    "    # Basic Physics\n",
    "    df = df.withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "    df = df.withColumn(\"Solid_PRCP\", when((col(\"PRCP\") > 0) & (col(\"TEMP\") < 2.0), col(\"PRCP\")).otherwise(0.0))\n",
    "    \n",
    "    # LAG FEATURES\n",
    "    windowSpec = Window.partitionBy(\"STATION\").orderBy(\"DATE\")\n",
    "    \n",
    "    df = df.withColumn(\"SNDP_lag1\", lag(\"SNDP\", 1).over(windowSpec)) \\\n",
    "           .withColumn(\"TEMP_lag1\", lag(\"TEMP\", 1).over(windowSpec)) \\\n",
    "           .withColumn(\"PRCP_lag1\", lag(\"PRCP\", 1).over(windowSpec))\n",
    "    \n",
    "    return df.na.drop(subset=[\"SNDP_lag1\", \"TEMP_lag1\"])\n",
    "\n",
    "train_df = add_features_with_lags(train_raw)\n",
    "test_df  = add_features_with_lags(test_raw)\n",
    "\n",
    "target_col = \"SNDP\"\n",
    "ignore_cols = [target_col, \"DATE\", \"STATION\", \"NAME\", \"features\", \"prediction\", \"FRSHTT\"]\n",
    "valid_types = ['int', 'bigint', 'float', 'double', 'tinyint', 'smallint']\n",
    "\n",
    "dtypes = train_df.dtypes\n",
    "feature_cols = [c for c, t in dtypes if t in valid_types and c not in ignore_cols]\n",
    "print(f\"   Final Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").setHandleInvalid(\"skip\")\n",
    "\n",
    "train_vec = assembler.transform(train_df)\n",
    "test_vec  = assembler.transform(test_df)\n",
    "\n",
    "train_vec.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "print(f\"   Final Training Rows: {train_vec.count():,}\")\n",
    "\n",
    "print(\"3. Training Ultimate Model (Best Params + Lags)...\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=target_col,\n",
    "    seed=42,\n",
    "    numTrees=int(best_params[\"numTrees\"]),\n",
    "    maxDepth=int(best_params[\"maxDepth\"]),\n",
    "    maxBins=int(best_params[\"maxBins\"]),\n",
    "    subsamplingRate=0.7 \n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model = rf.fit(train_vec)\n",
    "duration = time.time() - start_time\n",
    "\n",
    "print(f\"   Training completed in {duration/60:.2f} minutes.\")\n",
    "\n",
    "print(\"4. Evaluating and Logging final results...\")\n",
    "\n",
    "model.write().overwrite().save(os.path.join(model_output_dir, \"spark_model_ultimate\"))\n",
    "\n",
    "test_preds = model.transform(test_vec)\n",
    "\n",
    "metrics = evaluate_and_log(test_preds, target_col, duration, model_output_dir, MODEL_NAME)\n",
    "\n",
    "print(\"\\n--- PROCESS FINISHED ---\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
